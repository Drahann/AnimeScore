#!/usr/bin/env python3
"""
é‡æ–°è®¡ç®—æƒé‡è„šæœ¬
ç”¨äºåŸºäºç°æœ‰JSONæ–‡ä»¶é‡æ–°è®¡ç®—ç»¼åˆè¯„åˆ†å’Œæ’åï¼Œä½¿ç”¨æ–°çš„æƒé‡é…ç½®
"""
import asyncio
import sys
import json
from datetime import datetime
from pathlib import Path
from typing import List, Dict, Optional
import click
from loguru import logger

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from src.models.config import Config
from src.models.anime import AnimeInfo, AnimeScore, RatingData, WebsiteName, Season
from src.core.analyzer import AnimeAnalyzer

class WeightRecalculator:
    """æƒé‡é‡æ–°è®¡ç®—å™¨"""
    
    def __init__(self, config: Config):
        self.config = config
        
    def load_analysis_results(self, file_path: str) -> List[AnimeScore]:
        """ä»JSONæ–‡ä»¶åŠ è½½åˆ†æç»“æœ"""
        logger.info(f"ğŸ“‚ åŠ è½½åˆ†æç»“æœ: {file_path}")
        
        with open(file_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        anime_scores = []
        for ranking in data['rankings']:
            # é‡å»ºAnimeInfo
            anime_info = AnimeInfo(
                title=ranking['title'],
                title_english=ranking.get('title_english'),
                title_japanese=ranking.get('title_japanese'),
                title_chinese=ranking.get('title_chinese'),
                anime_type=ranking.get('anime_type'),
                episodes=ranking.get('episodes'),
                start_date=ranking.get('start_date'),
                studios=ranking.get('studios', []),
                genres=ranking.get('genres', []),
                year=ranking.get('year'),
                poster_image=ranking.get('poster_image'),
                cover_image=ranking.get('cover_image'),
                banner_image=ranking.get('banner_image'),
                external_ids={}
            )
            
            # é‡å»ºè¯„åˆ†æ•°æ®
            ratings = []
            for rating in ranking['ratings']:
                try:
                    website = WebsiteName(rating['website'])
                except ValueError:
                    logger.warning(f"æœªçŸ¥ç½‘ç«™: {rating['website']}")
                    continue
                    
                rating_data = RatingData(
                    website=website,
                    raw_score=rating['raw_score'],
                    vote_count=rating['vote_count'],
                    site_rank=rating.get('site_rank', 0),
                    site_mean=0.0,  # ä¼šé‡æ–°è®¡ç®—
                    site_std=0.0,   # ä¼šé‡æ–°è®¡ç®—
                    url=rating.get('url', '')
                )
                ratings.append(rating_data)
            
            anime_score = AnimeScore(
                anime_info=anime_info,
                ratings=ratings
            )
            anime_scores.append(anime_score)
        
        logger.info(f"âœ… æˆåŠŸåŠ è½½ {len(anime_scores)} ä¸ªåŠ¨æ¼«æ•°æ®")
        return anime_scores
    
    def save_recalculated_results(self, analysis, output_dir: str, output_formats: List[str]):
        """ä¿å­˜é‡æ–°è®¡ç®—åçš„ç»“æœ"""
        from pathlib import Path
        
        output_path = Path(output_dir)
        output_path.mkdir(parents=True, exist_ok=True)
        
        # ç”Ÿæˆæ–‡ä»¶å
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        season_str = f"{analysis.season.value}_{analysis.year}"
        base_filename = f"anime_ranking_{season_str}_weights_recalculated_{timestamp}"
        
        # å‡†å¤‡æ•°æ®
        results_data = {
            "analysis_info": {
                "season": analysis.season.value,
                "year": analysis.year,
                "analysis_date": analysis.analysis_date.isoformat(),
                "total_anime_count": analysis.total_anime_count,
                "analyzed_anime_count": analysis.analyzed_anime_count,
                "weights_recalculated": True,
                "recalculation_date": datetime.now().isoformat(),
                "platform_weights": dict(self.config.model.platform_weights)
            },
            "rankings": []
        }
        
        # è½¬æ¢åŠ¨æ¼«è¯„åˆ†æ•°æ®
        for i, anime_score in enumerate(analysis.anime_scores, 1):
            # å¤„ç†æ—¥æœŸåºåˆ—åŒ–
            start_date = anime_score.anime_info.start_date
            if hasattr(start_date, 'isoformat'):
                start_date = start_date.isoformat()
            elif start_date is not None:
                start_date = str(start_date)

            anime_data = {
                "rank": i,
                "title": anime_score.anime_info.title,
                "title_english": anime_score.anime_info.title_english,
                "title_japanese": anime_score.anime_info.title_japanese,
                "title_chinese": anime_score.anime_info.title_chinese,
                "anime_type": anime_score.anime_info.anime_type.value if anime_score.anime_info.anime_type else None,
                "episodes": anime_score.anime_info.episodes,
                "start_date": start_date,
                "studios": anime_score.anime_info.studios,
                "genres": anime_score.anime_info.genres,
                "composite_score": anime_score.composite_score.final_score if anime_score.composite_score else 0,
                "confidence": anime_score.composite_score.confidence if anime_score.composite_score else 0,
                "total_votes": anime_score.composite_score.total_votes if anime_score.composite_score else 0,
                "website_count": len(anime_score.ratings),
                "poster_image": anime_score.anime_info.poster_image,
                "cover_image": anime_score.anime_info.cover_image,
                "banner_image": anime_score.anime_info.banner_image,
                "percentile": anime_score.composite_score.percentile if anime_score.composite_score else None,
                "ratings": []
            }
            
            # æ·»åŠ è¯„åˆ†æ•°æ®
            for rating in anime_score.ratings:
                rating_data = {
                    "website": rating.website.value,
                    "raw_score": rating.raw_score,
                    "vote_count": rating.vote_count,
                    "site_rank": rating.site_rank,
                    "url": rating.url
                }
                anime_data["ratings"].append(rating_data)
            
            results_data["rankings"].append(anime_data)
        
        # ä¿å­˜JSONæ–‡ä»¶
        if 'json' in output_formats:
            json_file = output_path / f"{base_filename}.json"
            with open(json_file, 'w', encoding='utf-8') as f:
                json.dump(results_data, f, ensure_ascii=False, indent=2)
            logger.info(f"Results saved to {json_file}")
        
        # ä¿å­˜CSVæ–‡ä»¶
        if 'csv' in output_formats:
            csv_file = output_path / f"{base_filename}.csv"
            self._save_csv(results_data, csv_file)
            logger.info(f"CSV results saved to {csv_file}")
    
    def _save_csv(self, results_data: dict, csv_file: Path):
        """ä¿å­˜CSVæ ¼å¼çš„ç»“æœ"""
        import csv
        
        with open(csv_file, 'w', newline='', encoding='utf-8') as f:
            writer = csv.writer(f)
            
            # å†™å…¥è¡¨å¤´
            headers = ['Rank', 'Title', 'Title_English', 'Title_Japanese', 'Type', 'Episodes', 
                      'Start_Date', 'Studios', 'Genres', 'Composite_Score', 'Confidence', 
                      'Total_Votes', 'Website_Count']
            
            # æ·»åŠ ç½‘ç«™è¯„åˆ†åˆ—
            websites = ['ANILIST', 'BANGUMI', 'DOUBAN', 'FILMARKS', 'IMDB', 'MAL']
            for website in websites:
                headers.extend([f'{website}_Score', f'{website}_Votes'])
            
            writer.writerow(headers)
            
            # å†™å…¥æ•°æ®
            for ranking in results_data['rankings']:
                row = [
                    ranking['rank'],
                    ranking['title'],
                    ranking.get('title_english', ''),
                    ranking.get('title_japanese', ''),
                    ranking.get('anime_type', ''),
                    ranking.get('episodes', ''),
                    ranking.get('start_date', ''),
                    ', '.join(ranking.get('studios', [])),
                    ', '.join(ranking.get('genres', [])),
                    round(ranking['composite_score'], 6),
                    round(ranking['confidence'], 6),
                    ranking['total_votes'],
                    ranking['website_count']
                ]
                
                # æ·»åŠ ç½‘ç«™è¯„åˆ†æ•°æ®
                rating_dict = {r['website'].upper(): r for r in ranking['ratings']}
                for website in websites:
                    if website in rating_dict:
                        row.extend([rating_dict[website]['raw_score'], rating_dict[website]['vote_count']])
                    else:
                        row.extend(['', ''])
                
                writer.writerow(row)

@click.command()
@click.option('--config', '-c', default='config/config.yaml',
              help='é…ç½®æ–‡ä»¶è·¯å¾„')
@click.option('--input', '-i', required=True,
              help='è¾“å…¥çš„åˆ†æç»“æœJSONæ–‡ä»¶è·¯å¾„')
@click.option('--output', '-o', default=None,
              help='è¾“å‡ºç›®å½• (é»˜è®¤: final_resultsç›®å½•)')
@click.option('--formats', '-f', default='json,csv',
              help='è¾“å‡ºæ ¼å¼ (é€—å·åˆ†éš”: json,csv)')
@click.option('--verbose', '-v', is_flag=True,
              help='å¯ç”¨è¯¦ç»†æ—¥å¿—')
def main(config, input, output, formats, verbose):
    """æƒé‡é‡æ–°è®¡ç®—ç¨‹åº"""
    
    # è®¾ç½®æ—¥å¿—çº§åˆ«
    if verbose:
        logger.remove()
        logger.add(sys.stderr, level="DEBUG")
    
    logger.info("âš–ï¸ å¯åŠ¨æƒé‡é‡æ–°è®¡ç®—ç¨‹åº")
    
    try:
        # 1. åŠ è½½é…ç½®
        app_config = Config.load_from_file(config)
        logger.info(f"âœ… é…ç½®åŠ è½½æˆåŠŸ: {config}")
        logger.info(f"ğŸ“Š å½“å‰å¹³å°æƒé‡: {dict(app_config.model.platform_weights)}")
        
        # 2. åˆ›å»ºæƒé‡é‡æ–°è®¡ç®—å™¨
        recalculator = WeightRecalculator(app_config)
        
        # 3. åŠ è½½åˆ†æç»“æœ
        anime_scores = recalculator.load_analysis_results(input)
        
        # 4. é‡æ–°è®¡ç®—ç»¼åˆè¯„åˆ†å’Œæ’å
        logger.info("ğŸ”„ ä½¿ç”¨æ–°æƒé‡é‡æ–°è®¡ç®—ç»¼åˆè¯„åˆ†å’Œæ’å...")
        analyzer = AnimeAnalyzer(app_config)

        # é‡æ–°è®¡ç®—ç»¼åˆè¯„åˆ†
        ranked_scores = analyzer.calculate_composite_scores(anime_scores)

        # åˆ›å»ºåˆ†æç»“æœ
        from src.models.anime import SeasonalAnalysis
        analysis = SeasonalAnalysis(
            season=Season.SUMMER,
            year=2025,
            anime_scores=ranked_scores,
            total_anime_count=len(anime_scores),
            analyzed_anime_count=len(ranked_scores)
        )
        
        # 5. ä¿å­˜ç»“æœåˆ° final_results ç›®å½•
        output_dir = output or app_config.storage.final_results_dir
        output_formats = [fmt.strip() for fmt in formats.split(',')]
        
        recalculator.save_recalculated_results(analysis, output_dir, output_formats)
        
        logger.success("ğŸ‰ æƒé‡é‡æ–°è®¡ç®—å®Œæˆï¼")
        logger.info(f"ğŸ“ ç»“æœå·²ä¿å­˜åˆ°: {output_dir}")
        
    except Exception as e:
        logger.error(f"âŒ ç¨‹åºæ‰§è¡Œå¤±è´¥: {e}")
        raise


if __name__ == "__main__":
    main()
