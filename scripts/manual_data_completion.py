#!/usr/bin/env python3
"""
æ‰‹åŠ¨æ•°æ®è¡¥å…¨ç¨‹åº
è¯»å–åˆ†æç»“æœï¼Œè¯†åˆ«ç¼ºå¤±æ•°æ®çš„åŠ¨æ¼«ï¼Œå…è®¸ç”¨æˆ·æ‰‹åŠ¨è¾“å…¥è¯„åˆ†ï¼Œç„¶åé‡æ–°è®¡ç®—æ’å
"""
import asyncio
import json
import sys
from pathlib import Path
from typing import List, Dict, Optional
import click
from datetime import datetime

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from src.models.config import Config
from src.models.anime import AnimeScore, AnimeInfo, RatingData, WebsiteName
from src.core.analyzer import AnimeAnalyzer
# ç§»é™¤ä¸å­˜åœ¨çš„å¯¼å…¥
from loguru import logger


class ManualDataCompletion:
    """æ‰‹åŠ¨æ•°æ®è¡¥å…¨ç±»"""
    
    def __init__(self, config: Config):
        self.config = config
        self.analyzer = AnimeAnalyzer(config)
        self.enabled_websites = self._get_enabled_websites()
        
    def _get_enabled_websites(self) -> List[WebsiteName]:
        """è·å–å¯ç”¨çš„ç½‘ç«™åˆ—è¡¨ï¼ˆæ’é™¤æ•°æ®è¡¥å…¨æ’é™¤åˆ—è¡¨ä¸­çš„ç½‘ç«™ï¼‰"""
        enabled_websites = []
        excluded_websites = set(self.config.data_completion.excluded_websites)

        for website_name, website_config in self.config.websites.items():
            if website_config.enabled and website_name not in excluded_websites:
                try:
                    website_enum = WebsiteName(website_name)
                    enabled_websites.append(website_enum)
                except ValueError:
                    continue

        logger.info(f"ğŸ“Š æ‰‹åŠ¨è¡¥å…¨å¯ç”¨çš„ç½‘ç«™: {[w.value for w in enabled_websites]}")
        if excluded_websites:
            logger.info(f"ğŸ“Š æ‰‹åŠ¨è¡¥å…¨æ’é™¤çš„ç½‘ç«™: {list(excluded_websites)}")

        return enabled_websites

    def find_latest_results_file(self) -> str:
        """æŸ¥æ‰¾æœ€æ–°çš„ç»“æœæ–‡ä»¶ï¼ˆä¼˜å…ˆä» final_results ç›®å½•ï¼‰"""
        from pathlib import Path

        # é¦–å…ˆæ£€æŸ¥ final_results ç›®å½•
        final_results_dir = Path(self.config.storage.final_results_dir)
        if final_results_dir.exists():
            json_files = list(final_results_dir.glob("anime_ranking_*.json"))
            if json_files:
                latest_file = max(json_files, key=lambda x: x.stat().st_mtime)
                logger.info(f"ğŸ“‚ è‡ªåŠ¨é€‰æ‹© final_results ä¸­çš„æœ€æ–°æ–‡ä»¶: {latest_file.name}")
                logger.info(f"   (è¿™æ˜¯ç»è¿‡æ‰‹åŠ¨å¤„ç†çš„ç»“æœ)")
                return str(latest_file)

        # å¦‚æœ final_results æ²¡æœ‰æ–‡ä»¶ï¼Œåˆ™ä»æ™®é€š results ç›®å½•æŸ¥æ‰¾
        results_dir = Path(self.config.storage.results_dir)
        if not results_dir.exists():
            raise FileNotFoundError("ç»“æœç›®å½•ä¸å­˜åœ¨")

        json_files = list(results_dir.glob("anime_ranking_*.json"))
        if not json_files:
            raise FileNotFoundError("æ²¡æœ‰æ‰¾åˆ°åˆ†æç»“æœæ–‡ä»¶")

        latest_file = max(json_files, key=lambda x: x.stat().st_mtime)
        logger.info(f"ğŸ“‚ è‡ªåŠ¨é€‰æ‹© results ä¸­çš„æœ€æ–°æ–‡ä»¶: {latest_file.name}")
        logger.info(f"   (è¿™æ˜¯åŸå§‹åˆ†æç»“æœ)")
        return str(latest_file)

    def load_analysis_results(self, file_path: str) -> List[AnimeScore]:
        """ä»JSONæ–‡ä»¶åŠ è½½åˆ†æç»“æœ"""
        logger.info(f"ğŸ“‚ åŠ è½½åˆ†æç»“æœ: {file_path}")
        
        with open(file_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        anime_scores = []
        for ranking in data['rankings']:
            # é‡å»ºAnimeInfo
            anime_info = AnimeInfo(
                title=ranking['title'],
                title_english=ranking.get('title_english'),
                title_japanese=ranking.get('title_japanese'),
                title_chinese=ranking.get('title_chinese'),
                anime_type=ranking.get('anime_type'),
                episodes=ranking.get('episodes'),
                start_date=ranking.get('start_date'),
                studios=ranking.get('studios', []),
                genres=ranking.get('genres', []),
                poster_image=ranking.get('poster_image'),
                cover_image=ranking.get('cover_image'),
                banner_image=ranking.get('banner_image')
            )
            
            # é‡å»ºRatingDataåˆ—è¡¨
            ratings = []
            for rating in ranking['ratings']:
                website = WebsiteName(rating['website'])

                # ä»URLä¸­æå–IDå¹¶å­˜å‚¨åˆ°external_ids
                if website == WebsiteName.MAL and 'myanimelist.net/anime/' in rating.get('url', ''):
                    mal_id = rating['url'].split('/anime/')[-1].split('/')[0]
                    anime_info.external_ids[WebsiteName.MAL] = mal_id
                elif website == WebsiteName.ANILIST and 'anilist.co/anime/' in rating.get('url', ''):
                    anilist_id = rating['url'].split('/anime/')[-1].split('/')[0]
                    anime_info.external_ids[WebsiteName.ANILIST] = anilist_id
                elif website == WebsiteName.BANGUMI and 'bgm.tv/subject/' in rating.get('url', ''):
                    bangumi_id = rating['url'].split('/subject/')[-1].split('/')[0]
                    anime_info.external_ids[WebsiteName.BANGUMI] = bangumi_id
                elif website == WebsiteName.DOUBAN and 'douban.com/subject/' in rating.get('url', ''):
                    douban_id = rating['url'].split('/subject/')[-1].split('/')[0]
                    anime_info.external_ids[WebsiteName.DOUBAN] = douban_id

                rating_data = RatingData(
                    website=website,
                    raw_score=rating['raw_score'],
                    vote_count=rating['vote_count'],
                    site_mean=0.0,  # ä¼šé‡æ–°è®¡ç®—
                    site_std=0.0,   # ä¼šé‡æ–°è®¡ç®—
                    url=rating.get('url', '')
                )
                ratings.append(rating_data)
            
            anime_score = AnimeScore(
                anime_info=anime_info,
                ratings=ratings
            )
            anime_scores.append(anime_score)
        
        logger.info(f"âœ… æˆåŠŸåŠ è½½ {len(anime_scores)} ä¸ªåŠ¨æ¼«æ•°æ®")
        return anime_scores
    
    def identify_incomplete_anime(self, anime_scores: List[AnimeScore]) -> List[Dict]:
        """è¯†åˆ«æ•°æ®ä¸å®Œæ•´çš„åŠ¨æ¼«"""
        incomplete_anime = []
        
        for anime_score in anime_scores:
            existing_websites = {rating.website for rating in anime_score.ratings}
            missing_websites = set(self.enabled_websites) - existing_websites
            
            if missing_websites:
                incomplete_anime.append({
                    'anime_score': anime_score,
                    'existing_websites': existing_websites,
                    'missing_websites': missing_websites
                })
        
        # æŒ‰ç¼ºå¤±ç½‘ç«™æ•°é‡æ’åºï¼ˆç¼ºå¤±å°‘çš„ä¼˜å…ˆï¼‰
        incomplete_anime.sort(key=lambda x: len(x['missing_websites']))
        
        return incomplete_anime
    
    def display_anime_info(self, anime_score: AnimeScore):
        """æ˜¾ç¤ºåŠ¨æ¼«ä¿¡æ¯"""
        info = anime_score.anime_info
        print(f"\n{'='*60}")
        print(f"ğŸ“º åŠ¨æ¼«: {info.title}")
        if info.title_english:
            print(f"ğŸŒ è‹±æ–‡å: {info.title_english}")
        if info.anime_type:
            print(f"ğŸ“‹ ç±»å‹: {info.anime_type}")
        if info.episodes:
            print(f"ğŸ“º é›†æ•°: {info.episodes}")
        if info.start_date:
            print(f"ğŸ“… å¼€æ’­: {info.start_date}")
        if info.studios:
            print(f"ğŸ¢ åˆ¶ä½œ: {', '.join(info.studios[:3])}")
        if info.genres:
            print(f"ğŸ·ï¸ ç±»å‹: {', '.join(info.genres[:5])}")
        
        print(f"\nğŸ“Š ç°æœ‰è¯„åˆ†æ•°æ®:")
        for rating in anime_score.ratings:
            print(f"   {rating.website.value}: {rating.raw_score} ({rating.vote_count} ç¥¨)")
    
    def get_manual_rating(self, website: WebsiteName) -> Optional[RatingData]:
        """è·å–ç”¨æˆ·æ‰‹åŠ¨è¾“å…¥çš„è¯„åˆ†"""
        print(f"\nğŸ” è¯·ä¸º {website.value} ç½‘ç«™è¾“å…¥è¯„åˆ†æ•°æ®:")
        print("   (å¦‚æœæ²¡æœ‰æ•°æ®æˆ–è·³è¿‡ï¼Œç›´æ¥æŒ‰å›è½¦)")
        
        # è·å–è¯„åˆ†
        while True:
            score_input = input(f"   è¯„åˆ† (0.0-10.0): ").strip()
            if not score_input:
                return None
            
            try:
                score = float(score_input)
                if 0.0 <= score <= 10.0:
                    break
                else:
                    print("   âŒ è¯„åˆ†å¿…é¡»åœ¨ 0.0-10.0 ä¹‹é—´")
            except ValueError:
                print("   âŒ è¯·è¾“å…¥æœ‰æ•ˆçš„æ•°å­—")
        
        # è·å–æŠ•ç¥¨æ•°
        while True:
            votes_input = input(f"   æŠ•ç¥¨æ•° (é»˜è®¤100): ").strip()
            if not votes_input:
                votes = 100
                break
            
            try:
                votes = int(votes_input)
                if votes > 0:
                    break
                else:
                    print("   âŒ æŠ•ç¥¨æ•°å¿…é¡»å¤§äº0")
            except ValueError:
                print("   âŒ è¯·è¾“å…¥æœ‰æ•ˆçš„æ•´æ•°")
        
        # è·å–URLï¼ˆå¯é€‰ï¼‰
        url_input = input(f"   URL (å¯é€‰): ").strip()
        if not url_input:
            url_input = f"https://manual-input/{website.value}"
        
        return RatingData(
            website=website,
            raw_score=score,
            vote_count=votes,
            site_mean=0.0,  # ä¼šé‡æ–°è®¡ç®—
            site_std=0.0,   # ä¼šé‡æ–°è®¡ç®—
            url=url_input
        )
    
    def manual_completion_session(self, incomplete_anime: List[Dict]) -> Dict[str, List[RatingData]]:
        """æ‰‹åŠ¨è¡¥å…¨ä¼šè¯"""
        logger.info(f"ğŸ¯ å¼€å§‹æ‰‹åŠ¨æ•°æ®è¡¥å…¨ä¼šè¯ï¼Œå…± {len(incomplete_anime)} ä¸ªåŠ¨æ¼«éœ€è¦è¡¥å…¨")
        
        completed_data = {}
        
        for i, item in enumerate(incomplete_anime, 1):
            anime_score = item['anime_score']
            missing_websites = item['missing_websites']
            
            print(f"\nğŸ”¢ è¿›åº¦: {i}/{len(incomplete_anime)}")
            self.display_anime_info(anime_score)
            
            print(f"\nâŒ ç¼ºå¤±ç½‘ç«™: {[w.value for w in missing_websites]}")
            
            # è¯¢é—®æ˜¯å¦è¦è¡¥å…¨è¿™ä¸ªåŠ¨æ¼«
            while True:
                choice = input(f"\nâ“ æ˜¯å¦è¦ä¸ºè¿™ä¸ªåŠ¨æ¼«è¡¥å…¨æ•°æ®? (y/n/q): ").strip().lower()
                if choice in ['y', 'yes', 'æ˜¯']:
                    break
                elif choice in ['n', 'no', 'å¦']:
                    print("   â­ï¸ è·³è¿‡è¿™ä¸ªåŠ¨æ¼«")
                    break
                elif choice in ['q', 'quit', 'é€€å‡º']:
                    print("   ğŸ›‘ é€€å‡ºæ‰‹åŠ¨è¡¥å…¨")
                    return completed_data
                else:
                    print("   âŒ è¯·è¾“å…¥ y(æ˜¯)/n(å¦)/q(é€€å‡º)")
                    continue
            
            if choice in ['n', 'no', 'å¦']:
                continue
            
            # ä¸ºæ¯ä¸ªç¼ºå¤±çš„ç½‘ç«™è·å–æ•°æ®
            anime_completed_data = []
            for website in missing_websites:
                rating_data = self.get_manual_rating(website)
                if rating_data:
                    anime_completed_data.append(rating_data)
                    print(f"   âœ… å·²æ·»åŠ  {website.value} æ•°æ®: {rating_data.raw_score}")
            
            if anime_completed_data:
                completed_data[anime_score.anime_info.title] = anime_completed_data
                print(f"   ğŸ‰ æˆåŠŸä¸º {anime_score.anime_info.title} æ·»åŠ äº† {len(anime_completed_data)} æ¡æ•°æ®")
        
        return completed_data
    
    def merge_manual_data(self, anime_scores: List[AnimeScore], 
                         manual_data: Dict[str, List[RatingData]]) -> List[AnimeScore]:
        """åˆå¹¶æ‰‹åŠ¨è¾“å…¥çš„æ•°æ®"""
        logger.info(f"ğŸ”„ åˆå¹¶æ‰‹åŠ¨è¾“å…¥çš„æ•°æ®...")
        
        merged_count = 0
        
        for anime_score in anime_scores:
            anime_title = anime_score.anime_info.title
            
            if anime_title in manual_data:
                # æ·»åŠ æ‰‹åŠ¨è¾“å…¥çš„è¯„åˆ†æ•°æ®
                for rating_data in manual_data[anime_title]:
                    # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨è¯¥ç½‘ç«™çš„æ•°æ®
                    existing_websites = {r.website for r in anime_score.ratings}
                    
                    if rating_data.website not in existing_websites:
                        anime_score.ratings.append(rating_data)
                        merged_count += 1
                        logger.info(f"âœ… ä¸º {anime_title} æ·»åŠ  {rating_data.website.value} æ‰‹åŠ¨æ•°æ®")
        
        logger.info(f"ğŸ‰ æˆåŠŸåˆå¹¶ {merged_count} æ¡æ‰‹åŠ¨æ•°æ®")
        return anime_scores

    def _save_analysis_results(self, analysis, output_dir: str, output_formats: List[str], filename_suffix: str = ""):
        """ä¿å­˜åˆ†æç»“æœ"""
        from pathlib import Path

        output_path = Path(output_dir)
        output_path.mkdir(parents=True, exist_ok=True)

        # ç”Ÿæˆæ–‡ä»¶å
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        season_str = f"{analysis.season.value}_{analysis.year}"
        base_filename = f"anime_ranking_{season_str}{filename_suffix}_{timestamp}"

        # å‡†å¤‡æ•°æ®
        results_data = {
            "analysis_info": {
                "season": analysis.season.value,
                "year": analysis.year,
                "analysis_date": analysis.analysis_date.isoformat(),
                "total_anime_count": analysis.total_anime_count,
                "analyzed_anime_count": analysis.analyzed_anime_count,
                "manual_completion": True,
                "manual_completion_date": datetime.now().isoformat()
            },
            "rankings": []
        }

        # è½¬æ¢åŠ¨æ¼«è¯„åˆ†æ•°æ®
        for i, anime_score in enumerate(analysis.anime_scores, 1):
            anime_data = {
                "rank": i,
                "title": anime_score.anime_info.title,
                "title_english": anime_score.anime_info.title_english,
                "title_japanese": anime_score.anime_info.title_japanese,
                "title_chinese": anime_score.anime_info.title_chinese,
                "anime_type": anime_score.anime_info.anime_type.value if anime_score.anime_info.anime_type else None,
                "episodes": anime_score.anime_info.episodes,
                "start_date": anime_score.anime_info.start_date.isoformat() if anime_score.anime_info.start_date else None,
                "studios": anime_score.anime_info.studios,
                "genres": anime_score.anime_info.genres,
                "composite_score": anime_score.composite_score.final_score if anime_score.composite_score else 0,
                "confidence": anime_score.composite_score.confidence if anime_score.composite_score else 0,
                "total_votes": anime_score.composite_score.total_votes if anime_score.composite_score else 0,
                "website_count": len(anime_score.ratings),
                "poster_image": anime_score.anime_info.poster_image,
                "cover_image": anime_score.anime_info.cover_image,
                "banner_image": anime_score.anime_info.banner_image,
                "percentile": anime_score.composite_score.percentile if anime_score.composite_score else None,
                "ratings": []
            }

            # æ·»åŠ å„ç½‘ç«™è¯„åˆ†
            for rating in anime_score.ratings:
                rating_data = {
                    "website": rating.website.value,
                    "raw_score": rating.raw_score,
                    "vote_count": rating.vote_count,
                    "site_rank": getattr(rating, 'site_rank', None)
                }
                anime_data["ratings"].append(rating_data)

            results_data["rankings"].append(anime_data)

        # ä¿å­˜ä¸ºä¸åŒæ ¼å¼
        if "json" in output_formats:
            json_file = output_path / f"{base_filename}.json"
            with open(json_file, 'w', encoding='utf-8') as f:
                json.dump(results_data, f, ensure_ascii=False, indent=2)
            logger.info(f"Results saved to {json_file}")

        if "csv" in output_formats:
            csv_file = output_path / f"{base_filename}.csv"
            self._save_csv_results(results_data, csv_file)
            logger.info(f"CSV results saved to {csv_file}")

    def _save_csv_results(self, data, csv_path):
        """ä¿å­˜CSVæ ¼å¼ç»“æœ"""
        import csv

        # è·å–æ‰€æœ‰ç½‘ç«™
        all_websites = set()
        for anime in data['rankings']:
            for rating in anime.get('ratings', []):
                all_websites.add(rating['website'])

        all_websites = sorted(list(all_websites))

        with open(csv_path, 'w', newline='', encoding='utf-8-sig') as f:
            writer = csv.writer(f)

            # æ„å»ºè¡¨å¤´
            headers = [
                'Rank', 'Title', 'Title_English', 'Title_Japanese', 'Type', 'Episodes',
                'Start_Date', 'Studios', 'Genres', 'Composite_Score', 'Confidence',
                'Total_Votes', 'Website_Count'
            ]

            # æ·»åŠ å„ç½‘ç«™çš„è¯„åˆ†å’ŒæŠ•ç¥¨æ•°åˆ—
            for website in all_websites:
                headers.extend([
                    f"{website.upper()}_Score",
                    f"{website.upper()}_Votes"
                ])

            writer.writerow(headers)

            # å†™å…¥æ•°æ®
            for anime in data['rankings']:
                # åŸºç¡€ä¿¡æ¯
                row = [
                    anime['rank'],
                    anime['title'],
                    anime.get('title_english', ''),
                    anime.get('title_japanese', ''),
                    anime.get('anime_type', ''),
                    anime.get('episodes', ''),
                    anime.get('start_date', ''),
                    ', '.join(anime.get('studios', [])),
                    ', '.join(anime.get('genres', [])),
                    anime['composite_score'],
                    anime['confidence'],
                    anime['total_votes'],
                    anime['website_count']
                ]

                # å„ç½‘ç«™è¯„åˆ†
                website_ratings = {}
                for rating in anime.get('ratings', []):
                    website_ratings[rating['website']] = {
                        'score': rating['raw_score'],
                        'votes': rating['vote_count']
                    }

                # æ·»åŠ å„ç½‘ç«™çš„è¯„åˆ†å’ŒæŠ•ç¥¨æ•°
                for website in all_websites:
                    if website in website_ratings:
                        row.extend([
                            website_ratings[website]['score'],
                            website_ratings[website]['votes']
                        ])
                    else:
                        row.extend(['', ''])

                writer.writerow(row)


@click.command()
@click.option('--config', '-c', default='config/config.yaml',
              help='é…ç½®æ–‡ä»¶è·¯å¾„')
@click.option('--input', '-i', default=None,
              help='è¾“å…¥çš„åˆ†æç»“æœJSONæ–‡ä»¶è·¯å¾„ (é»˜è®¤: è‡ªåŠ¨é€‰æ‹©æœ€æ–°æ–‡ä»¶)')
@click.option('--output', '-o', default=None,
              help='è¾“å‡ºç›®å½• (é»˜è®¤: ä»é…ç½®è¯»å–)')
@click.option('--formats', '-f', default='json,csv',
              help='è¾“å‡ºæ ¼å¼ (é€—å·åˆ†éš”: json,csv,xlsx)')
@click.option('--verbose', '-v', is_flag=True,
              help='å¯ç”¨è¯¦ç»†æ—¥å¿—')
def main(config, input, output, formats, verbose):
    """æ‰‹åŠ¨æ•°æ®è¡¥å…¨ç¨‹åº"""
    
    # è®¾ç½®æ—¥å¿—çº§åˆ«
    if verbose:
        logger.remove()
        logger.add(sys.stderr, level="DEBUG")
    
    logger.info("ğŸš€ å¯åŠ¨æ‰‹åŠ¨æ•°æ®è¡¥å…¨ç¨‹åº")
    
    try:
        # 1. åŠ è½½é…ç½®
        app_config = Config.load_from_file(config)
        logger.info(f"âœ… é…ç½®åŠ è½½æˆåŠŸ: {config}")
        
        # 2. åˆ›å»ºæ‰‹åŠ¨è¡¥å…¨å™¨
        manual_completion = ManualDataCompletion(app_config)

        # 3. ç¡®å®šè¾“å…¥æ–‡ä»¶
        if input is None:
            logger.info("ğŸ” æœªæŒ‡å®šè¾“å…¥æ–‡ä»¶ï¼Œè‡ªåŠ¨æŸ¥æ‰¾æœ€æ–°ç»“æœ...")
            input_file = manual_completion.find_latest_results_file()
        else:
            input_file = input
            logger.info(f"ğŸ“‚ ä½¿ç”¨æŒ‡å®šçš„è¾“å…¥æ–‡ä»¶: {input_file}")

        # 4. åŠ è½½åˆ†æç»“æœ
        anime_scores = manual_completion.load_analysis_results(input_file)
        
        # 5. è¯†åˆ«ä¸å®Œæ•´çš„åŠ¨æ¼«
        incomplete_anime = manual_completion.identify_incomplete_anime(anime_scores)
        
        if not incomplete_anime:
            logger.info("ğŸ‰ æ‰€æœ‰åŠ¨æ¼«æ•°æ®éƒ½æ˜¯å®Œæ•´çš„ï¼Œæ— éœ€æ‰‹åŠ¨è¡¥å…¨ï¼")
            return
        
        logger.info(f"ğŸ“Š å‘ç° {len(incomplete_anime)} ä¸ªåŠ¨æ¼«éœ€è¦æ‰‹åŠ¨è¡¥å…¨æ•°æ®")
        
        # æ˜¾ç¤ºæ¦‚è§ˆ
        print(f"\nğŸ“‹ æ•°æ®ä¸å®Œæ•´çš„åŠ¨æ¼«æ¦‚è§ˆ:")
        for i, item in enumerate(incomplete_anime[:10], 1):  # åªæ˜¾ç¤ºå‰10ä¸ª
            anime = item['anime_score']
            missing = len(item['missing_websites'])
            print(f"   {i}. {anime.anime_info.title} (ç¼ºå¤± {missing} ä¸ªç½‘ç«™)")
        
        if len(incomplete_anime) > 10:
            print(f"   ... è¿˜æœ‰ {len(incomplete_anime) - 10} ä¸ªåŠ¨æ¼«")
        
        # 5. æ‰‹åŠ¨è¡¥å…¨ä¼šè¯
        manual_data = manual_completion.manual_completion_session(incomplete_anime)
        
        if not manual_data:
            logger.info("â„¹ï¸ æ²¡æœ‰æ‰‹åŠ¨è¾“å…¥ä»»ä½•æ•°æ®ï¼Œç¨‹åºç»“æŸ")
            return
        
        # 6. åˆå¹¶æ‰‹åŠ¨æ•°æ®
        updated_scores = manual_completion.merge_manual_data(anime_scores, manual_data)
        
        # 7. é‡æ–°è®¡ç®—æ’å
        logger.info("ğŸ§® é‡æ–°è®¡ç®—ç»¼åˆè¯„åˆ†å’Œæ’å...")
        ranked_scores = manual_completion.analyzer.calculate_composite_scores(updated_scores)
        
        # 8. ä¿å­˜ç»“æœåˆ° final_results ç›®å½•
        output_dir = output or app_config.storage.final_results_dir
        output_formats = [fmt.strip() for fmt in formats.split(',')]
        
        # åˆ›å»ºåˆ†æç»“æœå¯¹è±¡
        from src.models.anime import SeasonalAnalysis, Season
        
        # ä»åŸæ–‡ä»¶åæ¨æ–­å­£åº¦ä¿¡æ¯
        input_path = Path(input_file)
        if 'Summer_2025' in input_path.name:
            season = Season.SUMMER
            year = 2025
        else:
            season = Season.SUMMER  # é»˜è®¤
            year = 2025
        
        analysis = SeasonalAnalysis(
            season=season,
            year=year,
            anime_scores=ranked_scores,
            analysis_date=datetime.now()
        )
        
        # æ·»åŠ æ‰‹åŠ¨è¡¥å…¨æ ‡è®°
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename_suffix = f"_manual_completed_{timestamp}"

        manual_completion._save_analysis_results(analysis, output_dir, output_formats, filename_suffix)
        
        # 9. æ˜¾ç¤ºæœ€ç»ˆç»Ÿè®¡
        website_counts = {}
        for anime_score in ranked_scores:
            count = len(anime_score.ratings)
            website_counts[count] = website_counts.get(count, 0) + 1
        
        print(f"\nğŸ“Š æ‰‹åŠ¨è¡¥å…¨åçš„æ•°æ®å®Œæ•´æ€§ç»Ÿè®¡:")
        for count in sorted(website_counts.keys()):
            percentage = website_counts[count] / len(ranked_scores) * 100
            print(f"   {count}ä¸ªç½‘ç«™: {website_counts[count]}éƒ¨åŠ¨æ¼« ({percentage:.1f}%)")
        
        logger.info("ğŸ‰ æ‰‹åŠ¨æ•°æ®è¡¥å…¨å®Œæˆï¼")
        
    except Exception as e:
        logger.error(f"âŒ ç¨‹åºæ‰§è¡Œå¤±è´¥: {e}")
        raise


if __name__ == "__main__":
    main()
