#!/usr/bin/env python3
"""
éªŒè¯è±†ç“£å¢å¼ºçˆ¬è™«é›†æˆçŠ¶æ€
"""
import sys
from pathlib import Path
from loguru import logger

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

# é…ç½®æ—¥å¿—
logger.remove()
logger.add(sys.stdout, level="INFO", format="<green>{time:HH:mm:ss}</green> | <level>{level: <8}</level> | {message}")

def verify_integration():
    """éªŒè¯é›†æˆçŠ¶æ€"""
    logger.info("ğŸ” éªŒè¯è±†ç“£å¢å¼ºçˆ¬è™«é›†æˆçŠ¶æ€")
    
    success_count = 0
    total_tests = 0
    
    # æµ‹è¯•1: æ£€æŸ¥æ¨¡å—å¯¼å…¥
    total_tests += 1
    try:
        from src.scrapers.douban_enhanced import DoubanEnhancedScraper
        logger.success("âœ… è±†ç“£å¢å¼ºçˆ¬è™«æ¨¡å—å¯¼å…¥æˆåŠŸ")
        success_count += 1
    except Exception as e:
        logger.error(f"âŒ è±†ç“£å¢å¼ºçˆ¬è™«æ¨¡å—å¯¼å…¥å¤±è´¥: {e}")
    
    # æµ‹è¯•2: æ£€æŸ¥å·¥å‚æ³¨å†Œ
    total_tests += 1
    try:
        from src.scrapers.base import ScraperFactory
        from src.models.anime import WebsiteName
        
        available_scrapers = ScraperFactory.get_available_scrapers()
        
        if WebsiteName.DOUBAN in available_scrapers:
            logger.success("âœ… è±†ç“£çˆ¬è™«å·²åœ¨å·¥å‚ä¸­æ³¨å†Œ")
            success_count += 1
        else:
            logger.error("âŒ è±†ç“£çˆ¬è™«æœªåœ¨å·¥å‚ä¸­æ³¨å†Œ")
    except Exception as e:
        logger.error(f"âŒ å·¥å‚æ³¨å†Œæ£€æŸ¥å¤±è´¥: {e}")
    
    # æµ‹è¯•3: æ£€æŸ¥çˆ¬è™«å®ä¾‹åˆ›å»º
    total_tests += 1
    try:
        from src.scrapers.base import ScraperFactory
        from src.models.anime import WebsiteName
        from src.models.config import WebsiteConfig
        
        config = WebsiteConfig(
            enabled=True,
            base_url="https://movie.douban.com",
            rate_limit=5.0,
            timeout=60
        )
        
        scraper = ScraperFactory.create_scraper(WebsiteName.DOUBAN, config)
        
        if scraper and isinstance(scraper, DoubanEnhancedScraper):
            logger.success(f"âœ… è±†ç“£å¢å¼ºçˆ¬è™«å®ä¾‹åˆ›å»ºæˆåŠŸ: {type(scraper).__name__}")
            success_count += 1
        else:
            logger.error(f"âŒ è±†ç“£çˆ¬è™«å®ä¾‹åˆ›å»ºå¤±è´¥æˆ–ç±»å‹é”™è¯¯: {type(scraper) if scraper else None}")
    except Exception as e:
        logger.error(f"âŒ çˆ¬è™«å®ä¾‹åˆ›å»ºæ£€æŸ¥å¤±è´¥: {e}")
    
    # æµ‹è¯•4: æ£€æŸ¥å¢å¼ºåŠŸèƒ½
    total_tests += 1
    try:
        if scraper and hasattr(scraper, '_search_with_ajax_and_direct_access'):
            logger.success("âœ… ç¡®è®¤åŒ…å«AJAX+ç›´æ¥è®¿é—®ç»„åˆç­–ç•¥")
            success_count += 1
        else:
            logger.error("âŒ ç¼ºå°‘AJAX+ç›´æ¥è®¿é—®ç»„åˆç­–ç•¥")
    except Exception as e:
        logger.error(f"âŒ å¢å¼ºåŠŸèƒ½æ£€æŸ¥å¤±è´¥: {e}")
    
    # æµ‹è¯•5: æ£€æŸ¥é…ç½®æ–‡ä»¶
    total_tests += 1
    try:
        from src.models.config import Config

        config_path = project_root / "config" / "config.yaml"
        if config_path.exists():
            config = Config.load_from_file(str(config_path))

            # æ£€æŸ¥è±†ç“£æ˜¯å¦åœ¨å¯ç”¨çš„ç½‘ç«™åˆ—è¡¨ä¸­
            enabled_websites = config.get_enabled_websites()
            if 'douban' in enabled_websites:
                douban_config = config.get_website_config('douban')
                logger.success("âœ… è±†ç“£é…ç½®å·²å¯ç”¨")
                logger.info(f"   åŸºç¡€URL: {douban_config.base_url}")
                logger.info(f"   è¯·æ±‚é™åˆ¶: {douban_config.rate_limit}ç§’")
                logger.info(f"   è¶…æ—¶æ—¶é—´: {douban_config.timeout}ç§’")
                success_count += 1
            else:
                logger.warning("âš ï¸ è±†ç“£æœªåœ¨å¯ç”¨çš„ç½‘ç«™åˆ—è¡¨ä¸­")
        else:
            logger.error("âŒ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨")
    except Exception as e:
        logger.error(f"âŒ é…ç½®æ–‡ä»¶æ£€æŸ¥å¤±è´¥: {e}")
    
    # æµ‹è¯•6: æ£€æŸ¥åˆ†æå™¨é›†æˆ
    total_tests += 1
    try:
        from src.models.config import Config
        from src.core.analyzer import AnimeAnalyzer
        
        config = Config.load_from_file(str(config_path))
        analyzer = AnimeAnalyzer(config)
        
        scraper_status = analyzer.get_scraper_status()
        
        if 'douban' in scraper_status and scraper_status['douban']:
            logger.success("âœ… è±†ç“£çˆ¬è™«å·²é›†æˆåˆ°åˆ†æå™¨")
            
            # æ£€æŸ¥çˆ¬è™«ç±»å‹
            if WebsiteName.DOUBAN in analyzer.scrapers:
                douban_scraper = analyzer.scrapers[WebsiteName.DOUBAN]
                if isinstance(douban_scraper, DoubanEnhancedScraper):
                    logger.success("âœ… åˆ†æå™¨ä¸­ä½¿ç”¨çš„æ˜¯è±†ç“£å¢å¼ºçˆ¬è™«")
                    success_count += 1
                else:
                    logger.error(f"âŒ åˆ†æå™¨ä¸­ä½¿ç”¨çš„ä¸æ˜¯è±†ç“£å¢å¼ºçˆ¬è™«: {type(douban_scraper).__name__}")
            else:
                logger.error("âŒ è±†ç“£çˆ¬è™«æœªåœ¨åˆ†æå™¨ä¸­æ‰¾åˆ°")
        else:
            logger.error("âŒ è±†ç“£çˆ¬è™«æœªé›†æˆåˆ°åˆ†æå™¨æˆ–æœªå¯ç”¨")
    except Exception as e:
        logger.error(f"âŒ åˆ†æå™¨é›†æˆæ£€æŸ¥å¤±è´¥: {e}")
    
    # æ€»ç»“
    logger.info("=" * 60)
    logger.info(f"ğŸ“Š é›†æˆéªŒè¯ç»“æœ: {success_count}/{total_tests} é¡¹æµ‹è¯•é€šè¿‡")
    
    if success_count == total_tests:
        logger.success("ğŸ‰ è±†ç“£å¢å¼ºçˆ¬è™«å·²å®Œå…¨é›†æˆåˆ°ä¸»ç¨‹åºï¼")
        logger.info("âœ¨ ç°åœ¨å¯ä»¥ä½¿ç”¨ä»¥ä¸‹åŠŸèƒ½:")
        logger.info("   â€¢ AJAX+ç›´æ¥è®¿é—®ç»„åˆæœç´¢ç­–ç•¥")
        logger.info("   â€¢ æ™ºèƒ½ååçˆ¬è™«æŠ€æœ¯")
        logger.info("   â€¢ å®Œæ•´çš„è¯„åˆ†æ•°æ®è·å–")
        logger.info("   â€¢ å¤šé‡å¤‡ç”¨æœç´¢ç­–ç•¥")
        return True
    elif success_count >= total_tests * 0.8:
        logger.warning("âš ï¸ è±†ç“£å¢å¼ºçˆ¬è™«åŸºæœ¬é›†æˆæˆåŠŸï¼Œä½†æœ‰éƒ¨åˆ†é—®é¢˜éœ€è¦è§£å†³")
        return True
    else:
        logger.error("âŒ è±†ç“£å¢å¼ºçˆ¬è™«é›†æˆå¤±è´¥ï¼Œéœ€è¦æ£€æŸ¥é…ç½®å’Œä»£ç ")
        return False

def show_usage_guide():
    """æ˜¾ç¤ºä½¿ç”¨æŒ‡å—"""
    logger.info("=" * 60)
    logger.info("ğŸ“– ä½¿ç”¨æŒ‡å—:")
    logger.info("")
    logger.info("1. è¿è¡Œå­£åº¦åˆ†æ:")
    logger.info("   python scripts/run_seasonal_analysis.py --season 2024-1")
    logger.info("")
    logger.info("2. æµ‹è¯•è±†ç“£æœç´¢:")
    logger.info("   python scripts/test_ajax_direct_combo.py")
    logger.info("")
    logger.info("3. é…ç½®æ–‡ä»¶ä½ç½®:")
    logger.info("   config/config.yaml")
    logger.info("")
    logger.info("4. è±†ç“£é…ç½®é¡¹:")
    logger.info("   websites.douban.enabled: true")
    logger.info("   websites.douban.rate_limit: 5.0")
    logger.info("   websites.douban.timeout: 60")

def main():
    """ä¸»å‡½æ•°"""
    logger.info("ğŸ¬ è±†ç“£å¢å¼ºçˆ¬è™«é›†æˆéªŒè¯")
    
    success = verify_integration()
    
    if success:
        show_usage_guide()
    
    return success

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
