#!/usr/bin/env python3
"""
æµ‹è¯•è±†ç“£å¢å¼ºçˆ¬è™«é›†æˆåˆ°ä¸»ç¨‹åº
"""
import asyncio
import sys
from pathlib import Path
from loguru import logger

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from src.models.config import Config
from src.core.analyzer import AnimeAnalyzer
from src.models.anime import WebsiteName

# é…ç½®æ—¥å¿—
logger.remove()
logger.add(sys.stdout, level="INFO", format="<green>{time:HH:mm:ss}</green> | <level>{level: <8}</level> | {message}")

async def test_douban_integration():
    """æµ‹è¯•è±†ç“£çˆ¬è™«é›†æˆ"""
    logger.info("ğŸš€ æµ‹è¯•è±†ç“£å¢å¼ºçˆ¬è™«é›†æˆ")
    
    try:
        # åŠ è½½é…ç½®
        config_path = project_root / "config" / "config.yaml"
        if not config_path.exists():
            logger.error(f"é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_path}")
            return False
        
        config = Config.load_from_file(str(config_path))
        logger.success("âœ… é…ç½®åŠ è½½æˆåŠŸ")
        
        # åˆ›å»ºåˆ†æå™¨
        analyzer = AnimeAnalyzer(config)
        logger.success("âœ… åˆ†æå™¨åˆ›å»ºæˆåŠŸ")
        
        # æ£€æŸ¥è±†ç“£çˆ¬è™«æ˜¯å¦æ­£ç¡®æ³¨å†Œ
        scraper_status = analyzer.get_scraper_status()
        logger.info(f"ğŸ“Š çˆ¬è™«çŠ¶æ€: {scraper_status}")
        
        if WebsiteName.DOUBAN in analyzer.scrapers:
            douban_scraper = analyzer.scrapers[WebsiteName.DOUBAN]
            logger.success(f"âœ… è±†ç“£çˆ¬è™«å·²æ³¨å†Œ: {type(douban_scraper).__name__}")
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯å¢å¼ºç‰ˆ
            if hasattr(douban_scraper, '_search_with_ajax_and_direct_access'):
                logger.success("âœ… ç¡®è®¤ä¸ºè±†ç“£å¢å¼ºçˆ¬è™« (åŒ…å«AJAX+ç›´æ¥è®¿é—®ç»„åˆç­–ç•¥)")
            else:
                logger.warning("âš ï¸ å¯èƒ½ä¸æ˜¯å¢å¼ºç‰ˆè±†ç“£çˆ¬è™«")
            
            # æµ‹è¯•æœç´¢åŠŸèƒ½
            logger.info("ğŸ” æµ‹è¯•æœç´¢åŠŸèƒ½...")
            
            import aiohttp
            async with aiohttp.ClientSession() as session:
                try:
                    results = await douban_scraper.search_anime(session, "ä½ çš„åå­—")
                    
                    if results:
                        logger.success(f"âœ… æœç´¢æˆåŠŸï¼æ‰¾åˆ° {len(results)} ä¸ªç»“æœ")
                        
                        # æ˜¾ç¤ºç¬¬ä¸€ä¸ªç»“æœ
                        first_result = results[0]
                        douban_id = first_result.external_ids.get(WebsiteName.DOUBAN, "æœªçŸ¥")
                        logger.info(f"   é¦–ä¸ªç»“æœ: {first_result.title} (ID: {douban_id})")
                        
                        # æ£€æŸ¥æ˜¯å¦æœ‰è¯„åˆ†æ•°æ®
                        if hasattr(first_result, '_rating_data'):
                            rating = first_result._rating_data
                            logger.success(f"   â­ è¯„åˆ†: {rating.raw_score}, æŠ•ç¥¨: {rating.vote_count:,}")
                        
                        # æµ‹è¯•è¯„åˆ†è·å–
                        if douban_id != "æœªçŸ¥":
                            logger.info("ğŸ“Š æµ‹è¯•è¯„åˆ†è·å–...")
                            rating_data = await douban_scraper.get_anime_rating(session, douban_id)
                            
                            if rating_data:
                                logger.success(f"âœ… è¯„åˆ†è·å–æˆåŠŸ: {rating_data.raw_score}, æŠ•ç¥¨: {rating_data.vote_count:,}")
                            else:
                                logger.warning("âš ï¸ è¯„åˆ†è·å–å¤±è´¥")
                    else:
                        logger.warning("âŒ æœç´¢æœªæ‰¾åˆ°ç»“æœ")
                        
                except Exception as e:
                    logger.error(f"âŒ æœç´¢æµ‹è¯•å¤±è´¥: {e}")
        else:
            logger.error("âŒ è±†ç“£çˆ¬è™«æœªæ³¨å†Œ")
            return False
        
        return True
        
    except Exception as e:
        logger.error(f"âŒ é›†æˆæµ‹è¯•å¤±è´¥: {e}")
        return False

async def test_factory_registration():
    """æµ‹è¯•å·¥å‚æ³¨å†Œ"""
    logger.info("ğŸ­ æµ‹è¯•çˆ¬è™«å·¥å‚æ³¨å†Œ")
    
    try:
        from src.scrapers.base import ScraperFactory
        from src.models.anime import WebsiteName
        from src.models.config import WebsiteConfig
        
        # æ£€æŸ¥å¯ç”¨çˆ¬è™«
        available_scrapers = ScraperFactory.get_available_scrapers()
        logger.info(f"ğŸ“‹ å¯ç”¨çˆ¬è™«: {[ws.value for ws in available_scrapers]}")
        
        if WebsiteName.DOUBAN in available_scrapers:
            logger.success("âœ… è±†ç“£çˆ¬è™«å·²åœ¨å·¥å‚ä¸­æ³¨å†Œ")
            
            # å°è¯•åˆ›å»ºè±†ç“£çˆ¬è™«å®ä¾‹
            config = WebsiteConfig(
                enabled=True,
                base_url="https://movie.douban.com",
                rate_limit=3.0,
                timeout=30
            )
            
            scraper = ScraperFactory.create_scraper(WebsiteName.DOUBAN, config)
            
            if scraper:
                logger.success(f"âœ… è±†ç“£çˆ¬è™«å®ä¾‹åˆ›å»ºæˆåŠŸ: {type(scraper).__name__}")
                
                # æ£€æŸ¥æ˜¯å¦æ˜¯å¢å¼ºç‰ˆ
                if hasattr(scraper, '_search_with_ajax_and_direct_access'):
                    logger.success("âœ… ç¡®è®¤ä¸ºè±†ç“£å¢å¼ºçˆ¬è™«")
                    return True
                else:
                    logger.warning("âš ï¸ ä¸æ˜¯å¢å¼ºç‰ˆè±†ç“£çˆ¬è™«")
                    return False
            else:
                logger.error("âŒ è±†ç“£çˆ¬è™«å®ä¾‹åˆ›å»ºå¤±è´¥")
                return False
        else:
            logger.error("âŒ è±†ç“£çˆ¬è™«æœªåœ¨å·¥å‚ä¸­æ³¨å†Œ")
            return False
            
    except Exception as e:
        logger.error(f"âŒ å·¥å‚æ³¨å†Œæµ‹è¯•å¤±è´¥: {e}")
        return False

async def test_config_compatibility():
    """æµ‹è¯•é…ç½®å…¼å®¹æ€§"""
    logger.info("âš™ï¸ æµ‹è¯•é…ç½®å…¼å®¹æ€§")
    
    try:
        # æ£€æŸ¥é…ç½®æ–‡ä»¶
        config_path = project_root / "config" / "config.yaml"
        
        if config_path.exists():
            config = Config.load_from_file(str(config_path))
            
            # æ£€æŸ¥è±†ç“£é…ç½®
            if hasattr(config.websites, 'douban'):
                douban_config = config.websites.douban
                logger.success("âœ… è±†ç“£é…ç½®å­˜åœ¨")
                logger.info(f"   å¯ç”¨çŠ¶æ€: {douban_config.enabled}")
                logger.info(f"   åŸºç¡€URL: {douban_config.base_url}")
                logger.info(f"   è¯·æ±‚é™åˆ¶: {douban_config.rate_limit}ç§’")
                logger.info(f"   è¶…æ—¶æ—¶é—´: {douban_config.timeout}ç§’")
                
                return True
            else:
                logger.warning("âš ï¸ è±†ç“£é…ç½®ä¸å­˜åœ¨")
                return False
        else:
            logger.error("âŒ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨")
            return False
            
    except Exception as e:
        logger.error(f"âŒ é…ç½®å…¼å®¹æ€§æµ‹è¯•å¤±è´¥: {e}")
        return False

async def main():
    """ä¸»å‡½æ•°"""
    logger.info("ğŸ¬ è±†ç“£å¢å¼ºçˆ¬è™«é›†æˆæµ‹è¯•å¼€å§‹")
    
    # æµ‹è¯•ç»“æœ
    results = {}
    
    # 1. æµ‹è¯•å·¥å‚æ³¨å†Œ
    logger.info("=" * 50)
    results['factory'] = await test_factory_registration()
    
    # 2. æµ‹è¯•é…ç½®å…¼å®¹æ€§
    logger.info("=" * 50)
    results['config'] = await test_config_compatibility()
    
    # 3. æµ‹è¯•è±†ç“£é›†æˆ
    logger.info("=" * 50)
    results['integration'] = await test_douban_integration()
    
    # æ€»ç»“ç»“æœ
    logger.info("=" * 50)
    logger.info("ğŸ“Š æµ‹è¯•ç»“æœæ€»ç»“:")
    
    for test_name, success in results.items():
        status = "âœ… é€šè¿‡" if success else "âŒ å¤±è´¥"
        logger.info(f"   {test_name}: {status}")
    
    all_passed = all(results.values())
    
    if all_passed:
        logger.success("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼è±†ç“£å¢å¼ºçˆ¬è™«å·²æˆåŠŸé›†æˆåˆ°ä¸»ç¨‹åº")
    else:
        logger.error("âŒ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥é…ç½®å’Œä»£ç ")
    
    return all_passed

if __name__ == "__main__":
    success = asyncio.run(main())
    sys.exit(0 if success else 1)
