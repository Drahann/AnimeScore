"""
æ•°æ®è¡¥å…¨æ¨¡å—
ç”¨äºŽè¯†åˆ«å’Œè¡¥å…¨åŠ¨æ¼«è¯„åˆ†æ•°æ®ä¸­çš„ç¼ºå¤±ä¿¡æ¯
"""
import asyncio
import re
import aiohttp
from typing import List, Dict, Set, Optional, Tuple
from dataclasses import dataclass
from loguru import logger

from ..models.anime import AnimeScore, RatingData, WebsiteName, AnimeInfo
from ..models.config import Config
from ..scrapers.base import BaseWebsiteScraper


@dataclass
class MissingDataRecord:
    """ç¼ºå¤±æ•°æ®è®°å½•"""
    anime_score: AnimeScore
    missing_websites: Set[WebsiteName]
    available_websites: Set[WebsiteName]
    
    @property
    def completion_priority(self) -> int:
        """è¡¥å…¨ä¼˜å…ˆçº§ - åŸºäºŽå·²æœ‰ç½‘ç«™æ•°é‡"""
        return len(self.available_websites)


@dataclass
class SearchAttempt:
    """æœç´¢å°è¯•è®°å½•"""
    website: WebsiteName
    search_terms: List[str]
    success: bool
    found_data: Optional[RatingData] = None
    found_anime_info: Optional[AnimeInfo] = None


class DataCompletion:
    """æ•°æ®è¡¥å…¨å¼•æ“Ž"""
    
    def __init__(self, config: Config, scrapers: Dict[WebsiteName, BaseWebsiteScraper]):
        self.config = config
        self.completion_config = config.data_completion
        self.scrapers = scrapers
        self.missing_data_records: List[MissingDataRecord] = []
        self.completion_attempts: Dict[str, List[SearchAttempt]] = {}
        
    def identify_missing_data(self, anime_scores: List[AnimeScore]) -> List[MissingDataRecord]:
        """è¯†åˆ«ç¼ºå¤±æ•°æ®"""
        logger.info("ðŸ” å¼€å§‹è¯†åˆ«ç¼ºå¤±æ•°æ®...")
        
        missing_records = []
        enabled_websites = self._get_enabled_websites()
        
        for anime_score in anime_scores:
            # èŽ·å–å½“å‰åŠ¨æ¼«å·²æœ‰çš„ç½‘ç«™æ•°æ®
            available_websites = {rating.website for rating in anime_score.ratings}
            
            # æ‰¾å‡ºç¼ºå¤±çš„ç½‘ç«™
            missing_websites = enabled_websites - available_websites

            # æ£€æŸ¥æ˜¯å¦æ»¡è¶³æœ€å°çŽ°æœ‰ç½‘ç«™æ•°è¦æ±‚
            if (missing_websites and
                len(available_websites) >= self.completion_config.min_existing_websites):
                record = MissingDataRecord(
                    anime_score=anime_score,
                    missing_websites=missing_websites,
                    available_websites=available_websites
                )
                missing_records.append(record)
        
        # æŒ‰ä¼˜å…ˆçº§æŽ’åº - å·²æœ‰ç½‘ç«™æ•°å¤šçš„ä¼˜å…ˆè¡¥å…¨
        missing_records.sort(key=lambda x: x.completion_priority, reverse=True)
        
        logger.info(f"ðŸ“Š è¯†åˆ«åˆ° {len(missing_records)} ä¸ªåŠ¨æ¼«éœ€è¦æ•°æ®è¡¥å…¨")
        logger.info(f"ðŸ“ˆ å¹³å‡ç¼ºå¤±ç½‘ç«™æ•°: {sum(len(r.missing_websites) for r in missing_records) / len(missing_records):.1f}")
        
        self.missing_data_records = missing_records
        return missing_records
    
    async def complete_missing_data(self, missing_records: List[MissingDataRecord]) -> Tuple[Dict[str, List[RatingData]], Dict[str, List[AnimeInfo]]]:
        """è¡¥å…¨ç¼ºå¤±æ•°æ®"""
        logger.info(f"ðŸ”„ å¼€å§‹è¡¥å…¨ {len(missing_records)} ä¸ªåŠ¨æ¼«çš„ç¼ºå¤±æ•°æ®...")

        completed_data = {}
        completed_anime_info = {}
        total_attempts = 0
        successful_completions = 0
        
        for i, record in enumerate(missing_records, 1):
            anime_title = record.anime_score.anime_info.title
            logger.info(f"ðŸ“ [{i}/{len(missing_records)}] è¡¥å…¨åŠ¨æ¼«: {anime_title}")
            
            anime_completed_data = []
            anime_completed_info = []

            for website in record.missing_websites:
                if website not in self.scrapers:
                    continue

                scraper = self.scrapers[website]
                search_terms = self._generate_search_terms(record.anime_score)

                logger.debug(f"ðŸ” åœ¨ {website.value} æœç´¢: {search_terms}")

                # å°è¯•æœç´¢
                attempt = await self._attempt_search(scraper, website, search_terms, anime_title)
                total_attempts += 1

                # è®°å½•æœç´¢å°è¯•
                if anime_title not in self.completion_attempts:
                    self.completion_attempts[anime_title] = []
                self.completion_attempts[anime_title].append(attempt)

                if attempt.success and attempt.found_data:
                    anime_completed_data.append(attempt.found_data)
                    successful_completions += 1
                    logger.info(f"âœ… åœ¨ {website.value} æ‰¾åˆ°æ•°æ®: {attempt.found_data.raw_score}")

                    # ä¿å­˜AnimeInfoï¼ˆå¦‚æžœæœ‰çš„è¯ï¼‰
                    if attempt.found_anime_info:
                        anime_completed_info.append(attempt.found_anime_info)
                        logger.debug(f"âœ… åœ¨ {website.value} æ‰¾åˆ°åŠ¨æ¼«ä¿¡æ¯: {attempt.found_anime_info.title}")
                else:
                    logger.debug(f"âŒ åœ¨ {website.value} æœªæ‰¾åˆ°æ•°æ®")

            if anime_completed_data:
                completed_data[anime_title] = anime_completed_data
            if anime_completed_info:
                completed_anime_info[anime_title] = anime_completed_info
        
        success_rate = (successful_completions / total_attempts * 100) if total_attempts > 0 else 0
        logger.info(f"ðŸŽ‰ æ•°æ®è¡¥å…¨å®Œæˆ!")
        logger.info(f"ðŸ“Š æ€»å°è¯•: {total_attempts}, æˆåŠŸ: {successful_completions}, æˆåŠŸçŽ‡: {success_rate:.1f}%")

        return completed_data, completed_anime_info
    
    def _get_enabled_websites(self) -> Set[WebsiteName]:
        """èŽ·å–å¯ç”¨çš„ç½‘ç«™åˆ—è¡¨"""
        enabled_websites = set()
        
        for website_name, website_config in self.config.websites.items():
            if website_config.enabled:
                try:
                    website_enum = WebsiteName(website_name)
                    enabled_websites.add(website_enum)
                except ValueError:
                    continue
        
        return enabled_websites
    
    def _generate_search_terms(self, anime_score: AnimeScore) -> List[str]:
        """ç”Ÿæˆå¤šç§æœç´¢è¯ï¼ˆä¼˜å…ˆæ—¥æ–‡æ ‡é¢˜ï¼‰"""
        anime_info = anime_score.anime_info
        search_terms = []

        # 1. æ—¥æ–‡æ ‡é¢˜ï¼ˆæœ€é«˜ä¼˜å…ˆçº§ï¼‰
        if anime_info.title_japanese:
            search_terms.append(anime_info.title_japanese)
            # åŽ»æŽ‰ä¸€äº›å¯èƒ½çš„ä¿®é¥°è¯
            simplified_japanese = anime_info.title_japanese.replace('ç¬¬2æœŸ', '').replace('ç¬¬ï¼’æœŸ', '').replace('2nd Season', '').strip()
            if simplified_japanese != anime_info.title_japanese:
                search_terms.append(simplified_japanese)

        # 2. è‹±æ–‡æ ‡é¢˜
        if anime_info.title_english and anime_info.title_english != anime_info.title:
            search_terms.append(anime_info.title_english)

        # 3. åˆ«å
        if anime_info.alternative_titles:
            search_terms.extend(anime_info.alternative_titles[:2])  # åªå–å‰2ä¸ªåˆ«å

        # 4. åŽŸå§‹æ ‡é¢˜ï¼ˆç½—é©¬éŸ³ï¼‰
        if anime_info.title:
            search_terms.append(anime_info.title)

        # 5. ç®€åŒ–æ ‡é¢˜ï¼ˆåŽ»é™¤å­£æ•°ã€ç‰¹æ®Šç¬¦å·ç­‰ï¼‰
        if anime_info.title:
            simplified = self._simplify_title(anime_info.title)
            if simplified and simplified not in search_terms:
                search_terms.append(simplified)

        # 6. åŽ»é™¤æ‹¬å·å†…å®¹
        if anime_info.title:
            no_brackets = re.sub(r'\([^)]*\)', '', anime_info.title).strip()
            if no_brackets and no_brackets not in search_terms:
                search_terms.append(no_brackets)

        # åŽ»é‡å¹¶ä¿æŒé¡ºåº
        unique_search_terms = []
        for term in search_terms:
            if term and term not in unique_search_terms:
                unique_search_terms.append(term)

        return unique_search_terms[:5]  # é™åˆ¶æœ€å¤š5ä¸ªæœç´¢è¯
    
    def _simplify_title(self, title: str) -> str:
        """ç®€åŒ–æ ‡é¢˜"""
        # åŽ»é™¤å¸¸è§çš„ç‰¹æ®Šç¬¦å·å’ŒåŽç¼€
        simplified = title
        
        # åŽ»é™¤å¸¸è§åŽç¼€
        suffixes_to_remove = [
            r'\s*2nd Season$', r'\s*Season 2$', r'\s*S2$',
            r'\s*3rd Season$', r'\s*Season 3$', r'\s*S3$',
            r'\s*4th Season$', r'\s*Season 4$', r'\s*S4$',
            r'\s*Part 2$', r'\s*Part II$',
            r'\s*\(2025\)$', r'\s*\(2024\)$', r'\s*\(2023\)$',
            r'\s*OVA$', r'\s*ONA$', r'\s*Special$',
            r'\s*Movie$', r'\s*Film$'
        ]
        
        for suffix in suffixes_to_remove:
            simplified = re.sub(suffix, '', simplified, flags=re.IGNORECASE)
        
        # åŽ»é™¤å¤šä½™ç©ºæ ¼
        simplified = re.sub(r'\s+', ' ', simplified).strip()
        
        return simplified if simplified != title else ""
    
    def _remove_season_info(self, title: str) -> str:
        """åŽ»é™¤å­£æ•°ä¿¡æ¯"""
        # åŽ»é™¤å„ç§å­£æ•°è¡¨ç¤º
        season_patterns = [
            r'\s*2nd Season', r'\s*Season 2', r'\s*S2',
            r'\s*3rd Season', r'\s*Season 3', r'\s*S3', 
            r'\s*4th Season', r'\s*Season 4', r'\s*S4',
            r'\s*Part 2', r'\s*Part II', r'\s*Part III',
            r'\s*ç¶šç·¨', r'\s*ç¬¬äºŒå­£', r'\s*ç¬¬2å­£'
        ]
        
        result = title
        for pattern in season_patterns:
            result = re.sub(pattern, '', result, flags=re.IGNORECASE)
        
        return result.strip() if result.strip() != title else ""
    
    async def _attempt_search(self, scraper: BaseWebsiteScraper, website: WebsiteName,
                            search_terms: List[str], anime_title: str) -> SearchAttempt:
        """å°è¯•æœç´¢åŠ¨æ¼«æ•°æ®"""
        attempt = SearchAttempt(
            website=website,
            search_terms=search_terms,
            success=False
        )

        try:
            async with aiohttp.ClientSession() as session:
                for term in search_terms:
                    try:
                        # æœç´¢åŠ¨æ¼«
                        search_results = await scraper.search_anime(session, term)

                        if search_results:
                            # å–ç¬¬ä¸€ä¸ªç»“æžœèŽ·å–è¯¦ç»†ä¿¡æ¯
                            anime_data = search_results[0]

                            # ä»ŽAnimeInfoä¸­èŽ·å–å¯¹åº”ç½‘ç«™çš„ID
                            anime_id = anime_data.external_ids.get(website)
                            if not anime_id:
                                # å¦‚æžœæ²¡æœ‰external_idï¼Œå°è¯•ä½¿ç”¨å…¶ä»–IDå­—æ®µ
                                if website == WebsiteName.MAL and hasattr(anime_data, 'mal_id'):
                                    anime_id = str(anime_data.mal_id)
                                elif website == WebsiteName.ANILIST and hasattr(anime_data, 'anilist_id'):
                                    anime_id = str(anime_data.anilist_id)
                                elif website == WebsiteName.BANGUMI and hasattr(anime_data, 'bangumi_id'):
                                    anime_id = str(anime_data.bangumi_id)

                            if anime_id:
                                # èŽ·å–è¯„åˆ†æ•°æ®
                                rating_data = await scraper.get_anime_rating(session, anime_id)

                                if rating_data:
                                    attempt.success = True
                                    attempt.found_data = rating_data
                                    attempt.found_anime_info = anime_data  # ä¿å­˜AnimeInfo
                                    logger.debug(f"âœ… æœç´¢æˆåŠŸ: {term} -> {rating_data.raw_score}")
                                    return attempt
                                else:
                                    logger.debug(f"âš ï¸ æ‰¾åˆ°åŠ¨æ¼«ä½†æ— æ³•èŽ·å–è¯„åˆ†æ•°æ®: {anime_id}")
                            else:
                                logger.debug(f"âš ï¸ æ‰¾åˆ°åŠ¨æ¼«ä½†ç¼ºå°‘IDä¿¡æ¯: {anime_data.title}")

                    except Exception as e:
                        logger.debug(f"âŒ æœç´¢è¯ '{term}' å¤±è´¥: {e}")
                        continue

        except Exception as e:
            logger.warning(f"âš ï¸ æœç´¢ {anime_title} åœ¨ {website.value} æ—¶å‡ºé”™: {e}")

        return attempt
    
    def merge_completed_data(self, original_scores: List[AnimeScore],
                           completed_data: Dict[str, List[RatingData]],
                           completed_anime_info: Dict[str, List[AnimeInfo]]) -> List[AnimeScore]:
        """å°†è¡¥å…¨çš„æ•°æ®åˆå¹¶åˆ°åŽŸå§‹ç»“æžœä¸­"""
        logger.info("ðŸ”„ åˆå¹¶è¡¥å…¨æ•°æ®åˆ°åŽŸå§‹ç»“æžœ...")

        merged_count = 0
        merged_info_count = 0

        for anime_score in original_scores:
            anime_title = anime_score.anime_info.title

            # åˆå¹¶è¯„åˆ†æ•°æ®
            if anime_title in completed_data:
                for rating_data in completed_data[anime_title]:
                    # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨è¯¥ç½‘ç«™çš„æ•°æ®
                    existing_websites = {r.website for r in anime_score.ratings}

                    if rating_data.website not in existing_websites:
                        anime_score.ratings.append(rating_data)
                        merged_count += 1
                        logger.debug(f"âœ… ä¸º {anime_title} æ·»åŠ  {rating_data.website.value} æ•°æ®")

            # åˆå¹¶åŠ¨æ¼«ä¿¡æ¯
            if anime_title in completed_anime_info:
                for anime_info in completed_anime_info[anime_title]:
                    # åˆå¹¶æ ‡é¢˜ä¿¡æ¯
                    if anime_info.title_english and not anime_score.anime_info.title_english:
                        logger.info(f"   ðŸ“ æ·»åŠ è‹±æ–‡æ ‡é¢˜: '{anime_title}' -> '{anime_info.title_english}' (æ¥è‡ª {list(anime_info.external_ids.keys())[0].value if anime_info.external_ids else 'æœªçŸ¥'})")
                        anime_score.anime_info.title_english = anime_info.title_english
                        merged_info_count += 1

                    if anime_info.title_japanese and not anime_score.anime_info.title_japanese:
                        logger.info(f"   ðŸ“ æ·»åŠ æ—¥æ–‡æ ‡é¢˜: '{anime_title}' -> '{anime_info.title_japanese}' (æ¥è‡ª {list(anime_info.external_ids.keys())[0].value if anime_info.external_ids else 'æœªçŸ¥'})")
                        anime_score.anime_info.title_japanese = anime_info.title_japanese
                        merged_info_count += 1

                    if anime_info.title_chinese and not anime_score.anime_info.title_chinese:
                        website_name = list(anime_info.external_ids.keys())[0].value if anime_info.external_ids else 'æœªçŸ¥'
                        logger.info(f"   ðŸ‡¨ðŸ‡³ æ·»åŠ ä¸­æ–‡æ ‡é¢˜: '{anime_title}' -> '{anime_info.title_chinese}' (æ¥è‡ª {website_name})")
                        anime_score.anime_info.title_chinese = anime_info.title_chinese
                        merged_info_count += 1

                    # åˆå¹¶å›¾ç‰‡ä¿¡æ¯
                    if anime_info.poster_image and not anime_score.anime_info.poster_image:
                        logger.debug(f"   ðŸ–¼ï¸ æ·»åŠ æµ·æŠ¥å›¾ç‰‡: {anime_info.poster_image[:50]}...")
                        anime_score.anime_info.poster_image = anime_info.poster_image
                        merged_info_count += 1

                    if anime_info.cover_image and not anime_score.anime_info.cover_image:
                        anime_score.anime_info.cover_image = anime_info.cover_image
                        merged_info_count += 1

                    if anime_info.banner_image and not anime_score.anime_info.banner_image:
                        logger.debug(f"   ðŸ–¼ï¸ æ·»åŠ æ¨ªå¹…å›¾ç‰‡: {anime_info.banner_image[:50]}...")
                        anime_score.anime_info.banner_image = anime_info.banner_image
                        merged_info_count += 1

                    # åˆå¹¶å¤–éƒ¨ID
                    for website, external_id in anime_info.external_ids.items():
                        if website not in anime_score.anime_info.external_ids:
                            anime_score.anime_info.external_ids[website] = external_id
                            logger.debug(f"   ðŸ”— æ·»åŠ å¤–éƒ¨ID: {website.value} -> {external_id}")
                            merged_info_count += 1

        logger.info(f"ðŸŽ‰ æˆåŠŸåˆå¹¶ {merged_count} æ¡è¯„åˆ†æ•°æ®å’Œ {merged_info_count} æ¡åŠ¨æ¼«ä¿¡æ¯")
        return original_scores
    
    def get_completion_summary(self) -> Dict:
        """èŽ·å–è¡¥å…¨è¿‡ç¨‹æ‘˜è¦"""
        if not self.missing_data_records:
            return {}
        
        total_missing = len(self.missing_data_records)
        total_attempts = sum(len(attempts) for attempts in self.completion_attempts.values())
        successful_attempts = sum(
            1 for attempts in self.completion_attempts.values() 
            for attempt in attempts if attempt.success
        )
        
        return {
            "total_anime_with_missing_data": total_missing,
            "total_search_attempts": total_attempts,
            "successful_completions": successful_attempts,
            "success_rate": (successful_attempts / total_attempts * 100) if total_attempts > 0 else 0,
            "completion_details": {
                anime_title: [
                    {
                        "website": attempt.website.value,
                        "search_terms": attempt.search_terms,
                        "success": attempt.success,
                        "found_score": attempt.found_data.raw_score if attempt.found_data else None
                    }
                    for attempt in attempts
                ]
                for anime_title, attempts in self.completion_attempts.items()
            }
        }
